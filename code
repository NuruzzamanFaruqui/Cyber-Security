import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import LSTM, Dense
from keras.utils import to_categorical


# Load and preprocess the dataset (assuming it is already loaded as a Pandas DataFrame)
data = pd.read_csv('Data/CICIDS2017_sample.csv')
data = data[data['Label'].isin(['Benign', 'DoS', 'DDoS', 'Brute Force', 'MITM', 'Replay'])]

# Encode the labels
le = LabelEncoder()
data['Label'] = le.fit_transform(data['Label'])

# Split the dataset into features and labels
X = data.drop('Label', axis=1)
y = data['Label']

# Handle missing values by replacing them with the mean of the corresponding column
X = X.apply(lambda x: x.replace([np.inf, -np.inf], np.nan))  # Replace infinity values with NaN
X.fillna(X.mean(), inplace=True)  # Replace NaN with the mean of the column

# Normalize the features
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

# Reshape the input data to be suitable for LSTM (samples, time_steps, features)
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the LSTM model
model = Sequential()
model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dense(6, activation='softmax'))

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, shuffle=True)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Loss: {loss}, Accuracy: {accuracy}')
